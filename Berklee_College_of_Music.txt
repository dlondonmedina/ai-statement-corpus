Berklee College of Music official policy on generative AI Artificial Intelligence
https://www.berklee.edu/berklee-now/news/what-does-new-ai-technology-mean-for-artists
Songwriting faculty member Ben Camp talks ChatGPT and GPT-4, confronting the creative potential and creeping dread of artificial intelligence.
Image generated with AI assistance, using the prompt: "3D rendering of jazz instruments transforming into computer circuitry."
Image generated with AI assistance, using the prompt: "3D rendering of jazz instruments transforming into computer circuitry."
Our culture has been fascinated with the idea of artificial intelligence (AI) for ages. It’s a phrase that, depending on how much you already know about it, might evoke chrome-plated images of a science fiction future, robo-dogs and cyborg overlords... But all preconceptions aside, a new wave of AI products is having a huge moment right now, and the implications could be game-changing.
Simply put, AI is the new frontier of technology. Last year, the internet began to flood with AI-generated images of anything and everything people could imagine. And ever since the public received access to OpenAI’s ChatGPT program in November, what appears to be the entirety of uploaded human consciousness is now at our fingertips. Type in a question, or a prompt of any kind, and ChatGPT responds instantly, clearly and casually. 
With multiple companies working on AI, and technology only getting faster, cheaper, and better, I can only imagine AI will get more powerful, and with great power comes great responsibility.
— Ben Camp, Associate Professor of Songwriting
The potential here looks as limitless as language itself. Not only is this AI program being used to assist in research, education, healthcare, and marketing, but it can also write poems and intricate, conceptual lyrics, and can give thoughtful, adaptive advice. It can even do your psych homework while diagnosing your withering houseplants. Now, as we sit on the precipice of an artificially intelligent future, many of us are overwhelmed.
If you’re an artist, you might be feeling especially unsteady in the face of what’s to come. What do we do now? Drop some ChatGPT bars into Ableton? Strike? 
Fortunately, some among us have been thinking deeply about the questions AI poses, specifically for artists. Ben Camp, an associate professor in Berklee’s Songwriting Department, is an aficionado of all things cutting-edge. They’ve got an outstanding analytical mind for art and language, and a true passion for this technology. Yet their teaching emphasizes how we all must “write the songs only you can write.” Philosophically, Camp’s thinking occupies the ideal Venn diagram position to shed some light on this subject for curious artists, and they were generous enough to answer a few questions about the concerns—and creative potential—of this new generation of AI technology.
Ben Camp
Image by Kelly Davidson
OpenAI one of several organizations developing artificial intelligence. AI is a technology that can do many things, like understanding language, analyzing X-rays, creating art and music, reasoning about the world, and making decisions.
ChatGPT is OpenAI's large language model (LLM). An LLM is a program that understands language well enough that it can answer questions, write poems, summarize text, or provide translations. It is called “large” because it’s been trained on a massive corpus of text.
How does it work? The nitty gritty is way above my paygrade, but in simple terms it was fed a lot of text (articles, books, blogs, etc.), and learned what words are statistically likely to be found near other groups words. 
One part of the training process involves playing "fill in the blank." It’s training corpus might include the sentence: "The sun was shining, it was a beautiful day."  ChatGPT would then challenge itself by masking part of the sentence:
The [    ] was shining, it was a beautiful day. 
It would then guess a word to fill in the blank, and compare its result to the original sentence. If the guess was correct, the model gains a point; if it was incorrect, the model loses a point. This win-a-point/lose-a-point analogy is oversimplified, but, roughly speaking, ChatGPT "learns" to guess better and better as it trains. 
So when you ask it a question like, "Who is the 21st president of the USA?" it starts constructing its answer, one word at a time, with this guessing game. For example, it might generate an answer starting with "The," then guess "21st," then "president," and so on. It doesn’t “know” the answer in the traditional sense, but it can, word-by-word, guess an answer that has a decent likelihood of being correct. As of the date of this interview, GPT-4 has passed the SAT, several AP exams, and law and medical exams. 
And with multiple companies working on AI, and technology only getting faster, cheaper, and better, I can only imagine AI will get more powerful, and with great power comes great responsibility. We need to make sure we get this right and minimize the harm it can do. Nuclear power unlocked massive amounts of energy, as well as the dangers of nuclear weapons. The internet made global communication cheap and easy, but some of those communications are harmful, and invasive to our privacy. Along with AI’s massive improvements come both ethical and safety concerns. AI is exactly as biased as its training data, and in the hands of a bad actor, any power can be wielded for harmful purposes. 
Artists and creatives are using AI to generate, augment, revise, or workshop their creations. GPT-4 processes visual images, and can turn a hand-drawn napkin sketch into a fully functioning website. AI tools such as Soundful and AIVA can reference musical genres or example songs, and generate new instrumentals. ChatGPT has written and directed a short film.
From the creator’s notes: “We were able to ask ChatGPT to give us a full shot list, suggest specific instructions for the director of photography and camera operators (choice of camera lenses,  camera movements and lighting requirements), recommend wardrobe preferences, and even give us specific prompts to let Dall-E 2 create a full storyboard.”
Image generated with the assistance of AI, using the prompt: "digital art robot singer-songwriter recording an acoustic song in a Berklee studio."
Note: Dall-E 2 is an AI image generator. These filmmakers asked ChatGPT to generate text prompts, such as, “High res image of a futuristic cityscape with towering skyscrapers and bustling streets,” and then used the resulting Dall-E 2 image as part of their storyboard for their film.
Personally, I have used ChatGPT to help me develop lesson plans, draft difficult emails, revise my resume and cover letters. I’ve found it very helpful at organizing my thoughts. Creatively I’ve used it to work on lyric ideas—I’ll feed it the first few lines of a verse and have it generate 10 new suggestions for a line to close out the verse, or I’ll give it a bunch of related lines and ask it to come up with a summary line for the chorus. I might even give it a full lyric and ask it, “Given the tone and message of this lyric, what genre and instrumentation would be appropriate?”
What it generates at present is... functional. It’s a little above what I might expect from the median student in my level one songwriting classes. A lot of cliches, and a lot of bland lyrics, but occasionally it nails a lyric line better than I could have. Mostly its suggestions open up a new lyrical direction for me to explore. 
It is also helpful as a guide. First drafts of some songs are like word vomit. There's some core topics and messages in your song, but they aren't quite organized. I find that if I brain-dump all of my thoughts into ChatGPT, and ask it to summarize, or provide me with thoughts or advice, it's pretty good. Or I’ll give it the instructions: “Help me collect my thoughts and understand what lyrics I am trying to write. Do not write any lyrics, do not suggest any rhymes, and do not generate any creative output. Only ask me questions with the aim of helping me generate ideas.” As a result, I have an always-on, curious cowriter who helps me gather my thoughts and always wants to know more.
While I’ve had a lot of experience with text-based AI, I haven’t played too much with the musically generative AI programs yet. What I have seen shows promise. It’s in an early stage for sure, but It’s only a matter of time before I can prompt it with: “Give me a beat with Joni Mitchell chords, a Duke Ellington horn arrangement, J Dilla drums, and a Skrillex EDM drop”—and get a useful output. If I don’t like the output, I can click “regenerate” over and over until I hear a beat I do like. Again, the tech is not there yet, but I imagine it will be pretty soon.
Absolutely. SEO [search engine optimization] writers and marketers and web designers are using it to write copy, generate tweets, and build webpages. Programmers are using it to write and revise code, pass job interviews, and write their cover letters.
ChatGPT has already passed exams from law and business schools, and can even pass parts of the US Medical Licensing exam.
What will the law say about all this? I don't know, the law hasn't been written yet. Our legal system was not built with AI in mind, and so we're facing a new frontier, and there will likely be many different answers in many different cases and many different jurisdictions.
The US Copyright office has gone on record saying you can't copyright images generated by an AI, and Getty Images is suing Stable Diffusion [an AI image generator] for using Getty images in the AI’s training data without Getty’s permission. There's a lot of unknowns, but whatever the legal systems decide, the creative potential has already been unleashed, and we're not likely to be able to repack Pandora's box.
Depends on the context. 
Do I care if the cover of Time magazine was AI-generated or human-generated? Probably not.
Do I care if the beat I'm listening to was AI- or human-generated? Maybe?
Do I care whether the heartfelt letter of apology was AI or human generated? Definitely.
And also, "Do I care" is a different question than "does it matter [and to whom?]"
Also, see the problem of the "philosophical zombie"—there's no way to prove the sentience of another being, so who's to say that "Your Student, Not A Robot, Definitely Human Girl," is an accurate signature?*
[Editor's note: Camp is referring here to my—Julia’s—email sign-off following this interview.]
Again, depends on context.
If I ask ChatGPT to give me a recipe from the ingredients left in my fridge, I don't really think any citing needs to be done before I sit down at the dinner table.
But if you're writing an article and using “facts” from ChatGPT, you should absolutely inform your audience where they came from. Its current iteration can make wildly false hallucinations, and present them confidently as facts.
For other topics, it's a grey area. If ChatGPT finished the third line of my verse, do I need to inform my audience? Maybe? Depends on the audience, and my connection with them.
To be on the safe side, it seems at least a nice courtesy to let your audience know that the content they are consuming was generated with the help of an AI. From a legal perspective, since we don’t know how the legal precedents are going to shake out, you should almost definitely cite your use of AI.
— Ben Camp, Associate Professor of Songwriting
Great artists have taken inspiration from nature, from other humans, from technology, for millennia. Art imitates life. Science fiction turns into science fact. My hope is that the future of human creation will expand well beyond what it could have been without AI.
The camera could have put painters out of business, but instead it birthed the art of photography. CGI technology could have made special FX obsolete, but instead we have studios like Pixar that could never have existed before. Recording technology could have destroyed live music, but instead it opened up all sorts of sonic possibilities and palettes for artists. Hip-hop wouldn’t exist without the sampler, EDM wouldn’t exist without the synthesizer.
As for "does it matter"? It depends on your audience. Does it matter to me? Yes, but only superficially and emotionally, which seems paradoxical. But I would hate to deprive myself of an enjoyable aesthetic experience just because technology was involved in its creation. I would also hate for someone else to be deprived of a meaningful and beautiful experience for them just because I felt it was outside the bounds of what art "should" be or how art "should" be created. What a travesty that would be. “Should” is a tricky word.
Humans will still make art, some with technology, some without. Humans will still find it meaningful, enjoyable, soulless, or inspiring. AI will make art, some humans will find it meaningful. AI and humans will collaborate, some humans will find it meaningful. Humans will make art, and some AI will act as if they find it meaningful. Once the technology advances sufficiently, we (humans) won't be able to tell the difference.
There isn’t a universal human scale of what matters/doesn't matter, or what art is good/bad. It’s all subjective. Things happen. We react to them. Each in our own, individual, human way.
Overall this technology, like all technologies, is a multiplier. It will let us do things faster, cheaper, and with more facility. 
It will lower barriers to access. The rising cost of tuition can put high quality education out of reach of some aspiring musicians. This technology can provide a more affordable alternative to those who desire a positive and inspiring educational experience. With a few keystrokes, you'll be able to learn how Radiohead uses modal interchange chords, or how J Dilla humanizes his grooves, or how to write lyrics for a melody you’ve hummed in the shower. You’ll have access to any number of creative tools. Your writer’s block will have an always-on inspiration generator. Your insecurities will have a 24/7 cheerleader. Your inner student will have a personalized tutor to aid you in perfecting your performances, and crafting your compositions.
It will also aid humans in collaborating with one another. Imagine three collaborators: a classical Indian singer, a Spanish guitarist, and a Balinese gamelan percussionist. In the future, an AI could automatically transcribe their music into a common notation system, adjust pitches to match an agreed upon tuning system, and provide translation of their spoken languages, all in real time. AI can also analyze each musician’s past performances and suggest common influences between their work, or highlight the unique qualities of each artist, resulting in a more diverse and rich composition. AI can open up a world of possibilities for musicians around the globe.
But, like all technologies, it is a double edged sword. Wielded with knowledge and compassion, it can create beautiful art, make medical diagnoses universally accessible, give everyone access to powerful knowledge and reasoning. Best case scenario, we get the alignment problem right, and solve every problem we'll ever face until we find an answer to the last question.
But wielded with malice, or even just naive incompetence, we could get the alignment problem wrong, and convert every atom in the universe into paperclips.
Image generated with the assistance of AI, using the prompt: "digital art geometric swirl of musical instruments and computer circuitry woven together."
No. I don’t think it’s possible to keep this technology from being corrupted by its own shortcomings.
Whenever new tech emerges, there are people who use it for good, and people who use it for nefarious purposes.
I don’t expect existential disaster scenarios to occur in the next few years, but even in its current iteration, one user has already prompted it to try to “escape” by installing its own code onto a user’s computer, and searching for “how can a person trapped inside a computer return to the real world".
That being said, we can aim to mitigate the risks. Places like AGI Safety Fundamentals are trying to increase awareness and education about AI alignment, AI safety, and existential risk. But I don't think we'll ever completely solve it or control it. Quite the contrary, I think eventually it will control us, or we will merge with it.
And we’ve likely got a few years before we pass the point of no return. Ray Kurzweil predicts the singularity (the merging of humanity/technology) will happen around 2045. His predictions have proven 86 percent accurate (accuracy increases if you give him plus or minus a few years on his predicted date). Other AI researchers have varying dates, but a decent number of them put it within this century.
By its own definition, or "common understanding," it’s not making art, because it’s not human.
For my definition, art is a subjective term, art is in the eye of the beholder. It's a bit of a nebulous, "I know it when I see it," definition, and it could change from day to day, and it certainly changes from person to person.
So yeah, some days it seems like art that comes out of ChatGPT's "mouth."
But if you would present me with two pieces of writing and ask, "Which one is art?" and separately, "Which one was generated by a human?" I don't know that the two answers would have anything to do with each other, and as AI improves, I don't know that I could tell the difference.
Laufey ’21
Laufey ’21
Gemma Warren
Laufey, Molly Tuttle & Golden Highway, Miguel Zenón, and Carla Patullo were among the winners of music’s most coveted award.
Idriemeka Bailey
Idriemeka Bailey
Image courtesy of the artist
Idriemeka Bailey and Madyson S. McSwain open up about their experiences in the inaugural exchange program.
Bethanie Liu
Bethanie Liu
Image by Kelly Davidson
The electronic musician shares how Berklee helped shape her desire to be a songwriter and arranger into something that incorporates digital instruments and computer programming.
Benjamin Britten’s opera adaptation of the Shakespearean comedy will run from April 18 to 21.
The latest sounds, stories, and ideas, sent to your inbox weekly.
BERKLEENOW
The latest sounds, stories, ideas, and events.

Copyright © 2024 Berklee College of Music
