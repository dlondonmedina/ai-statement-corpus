Seattle University official policy on generative AI Artificial Intelligence
https://www.seattleu.edu/cdli/resources/chatgpt/
This page offers a brief introduction to ChatGPT, including suggestions on how it might be used in the classroom and an overview of its more problematic aspects. It also provides guidance on how to develop academic integrity and appropriate use policies for ChatGPT, as well as practical suggestions on how to mitigate plagiarism and cheating.
ChatGPT (Generative Pre-Trained Transformer) is an AI program that can generate natural language responses to a wide variety of prompts and questions. It is, at its core, a very sophisticated Chatbot. Developed by Open AI, it uses a large language model based on transformer technology to learn from massive amounts of data (mostly scraped from the internet). This allows it to respond to user prompts and engage in conversations, answer questions, write essays, solve mathematical equations, and write code in real time and in a fashion typically indistinguishable from a human’s response.
While generative AI and ChatGPT offer many possibilities for academics, they also have their shortcomings. One of the challenges for educators will be finding ways to incorporate generative AI into their curriculum in a way that enhances their teaching and prepares their students for the future while navigating these shortcomings.
As generative AI is rapidly evolving, this will be a long-term and iterative project. How you engage (or not) with ChatGPT and generative AI is of course up to you.  The Center for Digital Learning and Innovation will continue to stay abreast of developments in the use of AI in education. As best practices emerge, we will offer trainings and workshops for faculty to assist them in their experiments with ChatGPT and generative AI.
Here are some suggested steps faculty can take now to familiarize themselves with AI and address some of the issues it raises in the classroom:

ChatGPT is trained on text data sets derived from the internet, and its outputs can reflect the same biases expressed by content on the internet. While some companies are training their AI programs to avoid bias and offensive language, this itself is a source of controversy.
ChatGPT collects data from its users, including IP addresses, browser type and settings, and data on user prompts and interactions on the site. It can share your personal information with unspecified third parties. It is important to read Open AI’s privacy policy and never share your or a student’s personally identifiable information in a prompt.
The data sets ChatGPT is trained on give it vast amounts of general knowledge; however, it cannot access data behind paywalls or in specialized domains. It cannot reliably cite most academic source material, though domain-specific AI applications may change this. In addition, ChatGPT 4 cannot answer anything about anything that happened after 2021. It cannot tell you who won the 2023 World Series or Academy Award for Best Picture.
“Hallucinations” in AI is a developer’s term for “making stuff up.” ChatGPT makes stuff up. A lot. For example, if asked a question about academic writings it cannot access, ChatGPT will generate a plausible-sounding (though entirely fictional) answer. Like the internet upon which it is trained, it is sometimes just wrong.
For now, AI-generated content cannot be copyrighted; it is regarded as being in the public domain.  However, several lawsuits have been lodged by content creators who claim generative AI applications have used their copyrighted work without permission. Stay tuned. 
AI is already being used in some workplaces to generate entire documents, web pages, advertisements, and presentations; expect this to continue (for example, Microsoft plans to incorporate ChatGPT into its Microsoft 365 applications sometime this year). One of the challenges for educators will be to determine how much assistance from an AI software is too much.
Even given these issues, instructors may want to incorporate AI tools into their teaching, and it is likely our students will want to develop skills working with such tools. Here are some approaches you might want to experiment with in your classroom:
Use ChatGPT to brainstorm and generate ideas. This can help students with the “blank page” problem when beginning an assignment.
Have your students experiment with “prompt engineering” by writing different prompts on a topic and evaluating the different outputs from ChatGPT. Try to develop best practices in prompt writing that generate more useful and less biased outputs.
Conduct a dialogue on a course topic with ChatGPT. What does this reveal about the strengths and limitations of AI? Does it pass the Turing test?
Ask students to write a paper using ChatGPT as a “writing partner” and to consider what insights this process gives them regarding AI-Human collaboration. Have them reflect upon what AI does well and what it cannot do. What aspects of the assignment might remain uniquely human? How much AI assistance is too much?
Seattle University’s Strategic Directions call upon us to prepare our students to respond to the great challenges facing our society, including “rapid technological change and its societal and economic impacts”. Explore how using tools like ChatGPT might impact your discipline and different aspects of our society.
These are just a few early suggestions. Check out CDLI’s Generative AI and Education Padlet for more. We will continue to post suggestions for classroom activities with ChatGPT as we work with faculty and more research becomes available.
While Seattle University has revised its Academic Integrity Policy to account for the misuse of ChatGPT and generative AI, it is up to you to decide what tasks you would like students to accomplish without AI assistance and what tasks you think appropriate for ChatGPT.
Seattle University’s Academic Integrity Policy has been revised to define plagiarism as: “The use of the work or intellectual property of other persons or the outputs of Generative Artificial Intelligence (AI) programs (e.g., ChatGPT, DALL-E, Github Copilot) presented as one’s own work without appropriate citation or acknowledgment.” You should ensure your students are aware of these changes.
Seattle University’s Academic Integrity Policy has added this special note on cheating: “Faculty members may have specific policies regarding the use of AI programs, including prohibiting their use, and such policies should be included in the course syllabus.” Given that different instructors will have different views about the acceptable use of AI in their classes, you should be very clear about your policy.
Whether you allow the use of AI or not in your classes is of course up to you, but you should include a policy statement in your syllabus stating your expectations regarding student use of AI. Look over these Classroom Policies for AI Generative Tools and the resources in CDLI’s Padlet for examples of what instructors at other institutions have come up with.
If you’d like to explore ChatGPT and its possibilities a bit more before developing your policies, attend one of CDLI’s ChatGPT workshops or schedule an individual consultation.
While ChatGPT is very good at some learning tasks—like summarizing, comparing and contrasting, and writing five-paragraph essays—it falters when asked to perform more complex tasks. Getting creative with your assignment design can go a long way towards pre-empting cheating in your classes.
CDLI does not endorse or support any AI Detection software. We do not recommend making decisions regarding academic integrity based upon the outputs of AI Detection software.  While faculty can use such software, they should be aware that it is unreliable and probably won’t get much better. Not only does it regularly produce false negatives and positives, it is also very easy to beat—either by slightly altering the output, copying output from one AI text generator to another, or simply asking the AI to revise its output.
This will allow you to determine what AI does well and what it does not; focus your assignments on those tasks that AI has difficulty successfully completing. Evaluating AI outputs against your own rubrics or resources like the AACU VALUE rubrics will give you a good idea of AI’s limitations.
ChatGPT excels at retrieving data, comparing and contrasting, and summarizing knowledge—tasks associated with the lower-level domains of Bloom’s Taxonomy. Design your assignments around the higher-level domains of analysis, evaluation, and creation. 
This goes hand-in-glove with the suggestions above. Check out Resources for Faculty on Academic Integrity for more on authentic assessment.
Asking students to cite or respond to an academic article behind a paywall will prevent ChatGPT from successfully completing the assignment, though it will generate remarkably authentic-sounding nonsense. Requiring them to engage with recent developments or research in your field (post-2021) will also help prevent cheating with ChatGPT.
By using our website, you agree to our cookie policy
