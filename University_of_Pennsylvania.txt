University of Pennsylvania official policy on generative AI Artificial Intelligence
https://www.isc.upenn.edu/security/AI-guidance
Penn embraces innovations like generative artificial intelligence (“AI”) models in teaching, learning, research, and the effective stewardship of Penn’s resources.  To this end, this document provides guidelines for members of the Penn community who are using, or interested in using, AI in pursuit of Penn’s mission.
This document is scoped to generative AI using large language models provided by third parties.  Generative AI describes algorithms, such as ChatGPT and other large language models, that can be used to create new content, including text, code, and simulations. 
This statement is not intended as legal advice or an exhaustive set of best practices and should not be viewed as a final policy. The AI field is rapidly evolving in terms of technology, deployment models, third-party relationships, terms of service, regulatory landscape, and academic-industry partnership structures. It is anticipated that this document will be updated regularly and interact with other sources of policy, ethics, and governing legal authority.
Be transparent about the use of AI.  Disclose when a work product was created wholly or partially using an AI tool and, if appropriate, how AI was used to create the work product.
The user of AI should endeavor to validate the accuracy of created content with trusted first party sources and monitor the reliability of that content. Users are accountable for their use of content created by AI and should be wary of misinformation or “hallucinations” by AI tools (e.g., citations to publications or source materials that do not exist or references that otherwise distort the truth).
When using AI, keep in mind that these tools are often trained on large, unmoderated bodies of text, such as text posted to the internet.  This can result in the production of biased and other unintended content. The ability to avoid such biased content is still in the early stages of development.
Most AI tools and services use input and data from users of the tool to train the model.  Additionally, existing tools may incorporate AI features in their service offerings. For this reason, users of AI should avoid sharing personal or sensitive data with the tool and should not  input moderate or high-risk Penn data as defined by the Penn Data Risk Classification, or intellectual property, without:
Consultation with the Penn Center for Innovation, where intellectual property is involved.
It is not permissible under the Health Information Portability & Accountability Act (HIPAA) or Penn Medicine policy to share patient or research participant information in connection with open or public AI tools and services, such as ChatGPT. This is because, as currently configured, such open or public tools and services can use and share any data without regard to HIPAA restrictions and other protections. Therefore, individual patient data and patient data sets (even if deidentified) may not be exposed to open or public AI tools or services, absent institutional approval.  
When using AI to write computer code or when creating new technology that leverages AI it is important to be aware of the new kinds of cyberattacks that are being used against AI users.  Review the Office of Information Security guidance on these risks or consult with the Office of Information Security if in doubt. 
The rise of AI models has led to a significant increase in individuals and organizations scraping (i.e., copying) information posted on the internet for the purpose of training new AI models.  Be aware that any data posted publicly will likely be scraped and used in this way by third parties.  Similarly, while these practices are common, their legality and the potential consequences of these actions are currently being developed but remain unresolved at the time this guidance was issued. 
Members of the Penn community should adhere to established principles of respect for intellectual property, particularly copyrights when considering the creation of new data sets for training AI models.  Avoid uploading confidential and/or proprietary information to AI platforms prior to seeking patent or copyright protection, as doing so could jeopardize IP rights.
While automating tasks using AI may improve operational efficiency for University Business processes, oversight and review of the use of AI and verification of its outputs for these University business processes should be in place to ensure reliability, consistency, and accuracy.
This AI Guidance is largely focused on large language models, such as ChatGPT and Google Bard; but these principles apply generally to other machine learning and artificial intelligence technologies.
This Guidance applies to Penn faculty, staff, undergraduate students, pre-doctoral students, and post-doctoral trainees.
The Offices of Information Security and University Privacy developed this Guidance in collaboration with the Office of the Vice Provost for Education, the Office of the Vice Provost for Faculty, the Office of the Senior Vice Provost for Research, the Office of Clinical Research, the Office of General Counsel, Procurement, and the Penn Center of Innovation.
Yes, Schools, Centers, and other departments may publish more specific guidance on the use of AI to address certain situations or use cases.     
Visit ISC on LinkedIn
© 2024 THE UNIVERSITY OF PENNSYLVANIA — 3401 Walnut Street, Philadelphia, PA 19104 — Report accessibility issues and get help — For ISC Staff


