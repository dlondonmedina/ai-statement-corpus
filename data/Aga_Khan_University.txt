Aga Khan University
https://www.aku.edu/admissions/Documents/policy-use-of-generative-ai.pdf
THE USE OF GENERATIVE AI IN HIGHER EDUCATION AT AKU
POLICY STATEMENT
These guidelines outline principles for the use of Generative Artificial Intelligence (AI) in
higher education at Aga Khan University. These guidelines aim to ensure the effective and
responsible integration of Generative AI technologies into academic and administrative
processes. In this document, the term “AI” is used to refer to Generative AI technologies.
1. PURPOSE & SCOPE:
1.1 OpenAI’s ChatGPT-3 (Nov 30, 2022) delivers human-like responses on a variety of
subjects and has made generative AI tools easily accessible. This has led to AI tools becoming
rapidly integrated into various domains, including educational institutions, to enhance the
efficiency and effectiveness of processes. Hence, it is essential to engage in discussion and
establish guidelines at the University outlining the appropriate and ethical use of AI tools. By
doing so, we can ensure that the AI tools are used responsibly and prevent their use in
academic misconduct and other unethical practices.
1.2 After reviewing various policies and strategies from leading educational institutions,
related international bodies and policy-making authorities across the world, the University has
found that the principles outlined by the Russell Group of universities provide a
comprehensive framework for addressing the ethical and responsible use of generative AI
tools in academic settings. The University aims to follow guidelines on the use of AI tools in
education outlined by the following principles by the Russell Group1 as shown below:
1 Universities will support students and staff to become AI-literate.
2 (Faculty and) Staff should be equipped to support students to use generative AI
tools effectively and (appropriately responsibly) in their learning experience.
3 Universities will (review and) adapt (curriculum,) teaching and assessment to
incorporate the ethical use of generative AI and support equal access.
4 Universities will ensure academic rigour and integrity is upheld.
5 Universities will work collaboratively to share best practice as the technology
and its application in education evolves.
(Brackets indicate editorial modifications to the principles)
1.3 These guidelines apply to all faculty, staff, students, and other stakeholders involved in the
University's academic and administrative functions.
1.4 The guidelines and use of this technology will be in compliance with national data
protection laws.
2. MODIFICATION
2.1 These guidelines will be reviewed periodically and modified as and when necessary,
initially every two to three months during the first year of implementation.
3. ACADEMIC INTEGRATION
3.1 The University shall encourage the use of AI technologies to enhance teaching, learning,
research, and administrative processes, with a focus on improving efficiency and
effectiveness.
1 Russell Group. (2023, July 4). RG AI Principles. Retrieved from
https://russellgroup.ac.uk/media/6137/rg_ai_principles-final.pdf
3.2 AI tools and platforms may be utilised by faculty and staff to support assessments,
grading, administrative tasks, and other relevant areas.
3.3 Instructors and other staff should not copy/paste students’ work into Generative AI tools
either for feedback, assessment, or any other purpose without informing students because it
could lead to breach of data privacy.
4. USE OF AI TOOLS IN LEARNING
4.1 The University encourages instructors to support their students in using AI tools to
improve their critical thinking and facilitate learning.
4.2 If a student is uncertain about the assistance of an AI tool in a task, it is their responsibility
to seek clarification from their instructor and the available guidelines on the use of the
technology before incorporating material generated by that tool into their work.
4.3 As stated in the AKU Academic Integrity Policy2, a student is not allowed to submit or
present work acquired from other source(s) as their own. This includes any materials
generated by AI tools as well. Students are expected to paraphrase, reflect, and critique
information obtained from AI tools before including it in their work.
4.4 The University encourages students to use AI tools for facilitating learning and
assessments by helping them in evaluating and understanding new concepts and ideas to
generate their own academic work, within ethical and responsible boundaries. This includes,
but is not limited to:
i Developing ideas and thoughts by asking meaningful questions or suggestions
ii Personalising learning
iii Paraphrasing, improving grammar, punctuation, sentence construction and other
language skills on material written by the student.
iv Generating text, graphics, audio or any other materials based on appropriate prompts.
4.5 Whenever AI tools have been used by the student in their work, they must be
appropriately referenced and cited according to the instructions outlined by the University or
the publisher.
4.6 Course handbooks can provide further instructions.
2 Aga Khan University. (2022). Policy on Student Academic Integrity (KE-014). Retrieved
from https://www.aku.edu/admissions/Documents/policy-student-academic-integrity-ke-
014.pdf
5. CREDIBILITY OF AI GENERATED CONTENT
5.1 Most AI tools are pre-trained on large-scale datasets, which may contain biases, limited or
incorrect information. This is why content generated by such tools may be offensive,
inaccurate, incomplete, or not currently valid. Hence, AI tools cannot be considered a
completely reliable source of information.
5.2 AI tools must not be used as an authoritative source of study on a topic. Any AI generated
content used in research or assessments must be verified using credible sources to check for
factual inaccuracies and incomplete information.
5.3 Current AI tools rely on generating responses by analysing patterns and associations
within their training data rather than comprehending the meaning or context of the
information. Hence AI tools must not be used as the sole means of critical analysis of data.
Forming original ideas and critique based on data is an integral part of the research process,
and AI tools must not be relied on to generate opinions where reflection and reasoning are
required by the student.
6. HOW TO ACKNOWLEDGE WHEN AN AI TOOL IS USED
6.1 Content from generative AI is a nonrecoverable source as it cannot be retrieved or linked.
6.2 Any use of AI technology must be appropriately acknowledged and identified in any
submitted work. This includes, but is not limited to, the name, version, description, and date
of use for the AI tool.
6.3 Students must identify where and how they have used AI assistance in all their submitted
work.
6.4 Additionally, students must be able to produce a fully documented record of the prompts,
materials and outputs given to and generated by the AI tool, along with each work when
required.
7. USE OF AI TOOLS IN TEACHING
For this document, the term “instructors” is used to refer to all faculty and staff involved in
the teaching process including but not limited to those in support roles, teaching assistants,
technical assistants, researchers, mentors, and counsellors.
7.1 The University recommends instructors incorporate AI tools in facilitating teaching, and
encourages them to support their students in using similar tools to facilitate their learning and
assist their studies, where appropriate.
7.2 Programs may devise regulations for AI tools use. These regulations must not conflict
with the guidelines outlined in this document.
7.3 Instructors should seek evidence of original thought and critical thinking in submissions
made with AI assistance. Students must have documentation and be able to produce such
information when requested.
7.4 The University encourages instructors to design teaching material incorporating AI tools
creatively, ethically, and responsibly to support student learning.
7.5 Instructors are advised to review/adapt techniques to prioritise assessment tasks that
require higher-order thinking skills and promote critical analysis, reducing reliance on tasks
that can be easily accomplished by AI systems.
7.6 Although AI-detection tools exist, instructors are reminded that none of them have yet
been able to guarantee accurate detection. Therefore, instructors are strongly advised to
consider the academic and mental repercussions of false accusations on students for the
unethical use of AI tools.
7.7 If academic dishonesty or research misconduct is suspected, the AKU Student Academic
Integrity Policy, the AKU Research Misconduct Policy or other relevant policies will be
applied.
7.8 An instructor must seek permission from the student before submitting his/her work into
any AI tool for assessment, feedback, or any other purpose.
8. CITING GENERATIVE AI IN ASSIGNMENTS AND PUBLICATIONS
8.1 It is recommended to follow the publisher’s guidelines on citing AI tools.
8.2 For theses and dissertations, AKU recommends APA for making citations. Other citing
methods as required are also shown in the examples below.
APA 73:
Author of AI model used. (Year of AI model used). Name of AI model used (Version
of AI model used) [Type or description of AI model used]. Web address of AI model
used.
3 American Psychological Association. (2021, July 23). How to Cite ChatGPT and Other AI
Language Models in APA Style. Retrieved from https://apastyle.apa.org/blog/how-to-cite-
chatgpt
APA 7 - Example
OpenAI. (2022). ChatGPT (Dec 20 version) [Large language model].
https://chat.openai.com/
The full transcript of a response must be included in an appendix or other
supplementary materials.
Chicago (note):
Number Originator of the communication, medium, Day, Month, Year.
Chicago (note) - Example:
1OpenAI's ChatGPT AI language model, response to question from author, 7 February
2023.
MLA:
“Title of source” prompt. Name of AI Tool, version, Company, Date content was
generated, General web address of tool.
MLA - Example:
“Describe the symbolism of the green light in the book The Great Gatsby by F. Scott
Fitzgerald” prompt. ChatGPT, 13 Feb. version, OpenAI, 8 Mar. 2023,
chat.openai.com/chat.
