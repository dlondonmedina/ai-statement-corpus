Drexel University official policy on generative AI Artificial Intelligence
https://drexel.edu/provost/policies-calendars/policies/academic_integrity_artificial_intelligence/
Please Note: The following guidelines complement Drexel University's Academic Integrity policy and conduct process. The Provost's Office has submitted these guidelines for review as an official policy through the Policy Review Process from the Office of Compliance, Policy and Privacy Services. Supporting appendices, which can also be found at the bottom of these guidelines, include:
Appendix A: “AI Tools: Scope and Use at Drexel University”: This document highlights the spectrum of AI tools in terms of the level of assistance they provide. 
Appendix B: “AI Tools: Citation of Use at Drexel University”: This document shows how to cite the usage of AI tools. 
Appendix C: “AI Tools: Sample Syllabi Language”: This document provides simple sample syllabi language on the use of AI tools.

These guidelines on academic integrity pertaining to Artificial Intelligence clarify the existing Academic Integrity Policy and the Academic Integrity Conduct Process to explicitly address the use and misuse of Artificial Intelligence Tools in all contexts related to education and learning at Drexel University.
These guidelines are relevant to the entire University community, faculty, professional staff, students, or a combination of these groups.
For inquiries regarding these guidelines, please contact the Office of the Provost at provost@drexel.edu.
The following points are background for these guidelines:
Artificial Intelligence Tools are, and will increasingly be, a vital component of many academic and professional disciplines. Academic units have integrated Artificial Intelligence tools into their courses and curricula, and the University as a whole recognizes the enormous pedagogical value of these tools.
The landscape of Artificial Intelligence Tools is rapidly changing, including the names of the most commonly used tools, the wide variety of contexts and uses in which the tools are employed, and the scope and efficacy of these tools. Consequently, no attempt is made to catalog or taxonomize this landscape. Rather, Appendix A “AI Tools: Scope and Use at Drexel University” presents a partial snapshot of the current landscape, with the recognition this snapshot will require regular updates to maintain relevance.
The broad scope of the University's education and learning enterprise, including breadth of topic, level, pedagogy, and mode, as well as the broad scope of use of Artificial Intelligence Tools in education and learning naturally lead to a broad scope for the suitable use of these tools in the classroom. Consequently, a foundational component of these guidelines is that instructors have broad discretion to define the suitable use of Artificial Intelligence Tools in the classroom.
It is the right of the course instructor to decide whether AI Tools are to be permitted in the course and if they are allowed to describe precisely the conditions and criteria for use. Certain exceptions will apply for students with disabilities. Students requesting or requiring accommodations are encouraged to contact the Office of Disability Resources.
It is the responsibility of the instructor to include in the course syllabus a clearly written description of the permitted use of AI tools. It is strongly recommended that the instructor discuss this written description at the beginning of the course and as needed throughout the term. It is also expected that faculty describe precisely how students are expected to attribute / cite the use of AI tools. To assist faculty with communicating which AI tools are permitted in a course, Appendix A (“AI Tools: Scope and Use at Drexel University”) provides a checklist of common AI tools that faculty can customize based on their preference and include in the syllabus, and Appendix C (“AI Tools: Sample Syllabi Language”) provides language instructors may use in their syllabus to summarize their course policy on the use of AI.
Given the wide and dynamic landscape of AI Tools available for use by students in coursework, it is NOT required for the instructor to specify permitted use of every such tool. Instead, wherever there is a lack of clarity or specification, the default guidelines on the use of AI Tools in courses is that such tools are not permitted. Below are three important exceptions to this statement:
a. All databases and research tools provided by Drexel University Libraries are approved for use in coursework, unless such usage contradicts instructor guidance on coursework completion.
b. Appendix A (“AI Tools: Scope and Use at Drexel University”) includes a list of AI tools that are approved for use in coursework by default, unless such usage contradicts instructor guidance on coursework completion.
c. Certain exceptions will apply for students with disabilities. Students requesting or requiring accommodations are encouraged to contact the Office of Disability Resources.
It is the responsibility of the student to read, understand, and seek clarification from the instructor where necessary on the instructor's written and verbal descriptions of the acceptable use of AI in the course. If usage of AI Tool(s) is permitted by the instructor, students are obligated to follow the instructor's guidance regarding the nature of that usage.
If usage of AI Tool(s) is permitted by the instructor, students are obligated to follow the instructor's guidance regarding if and how that usage is to be attributed/cited in the submitted work. If no attribution / citation guidance is given by the instructor, the students should adopt the style typically used in the discipline most closely aligned with the course. Appendix B (“AI Tools: Citation of Use at Drexel University”) aims to assist students with the various citation rules and styles for AI and AI Tools.
If usage of AI Tool(s) is permitted by the instructor, the final work product that is submitted is nonetheless the responsibility of the student. It is important that students are aware that AI generated content may be false or biased, and students assume ownership of and responsibility for submitted work that may be violative of other university policies. Inappropriate or offensive content may be reported to Student Conduct & Care or other relevant university offices for consideration of appropriate next steps, if any.
The purpose of this section is to clarify the use and potential misuse of so-called “AI Detection Tools.” These tools aim to assess whether or not AI or an AI Tool has been used to create a digital object (e.g., text, audio, image, video); in this context this applies to any and all student submitted work. There is no restriction on the use of such tools by the instructor, but the instructor is urged to be aware of the potential misuse or misinterpretation of the outputs presented by these tools.
Such tools are often fallible; they may both assert the digital object was created by AI when it was not or assert the digital object was not created by AI when it was. Such tools often advertise “error rates” to describe the frequency or likelihood of these mistakes.
a. Users of AI Detection Tools should be aware that the method used by these tools to determine if AI was used is particularly likely to yield false positives in the cases of neurodivergent students and students for whom English is not their first language.
b. Recent research also indicates that AI Detection Tools yield false negatives where students use paraphrasing tools or edit the document after using AI.
The creators and distributors of such tools may misestimate the fallibility of the tool. Instructors are advised to exercise caution regarding the asserted level of accuracy.
In the context of plagiarism, for which the same or similar tools are often used, the tool is often able to provide “proof” to accompany an assertion of plagiarism in the form of demonstrating similarity between the object being assessed (i.e., the work submitted by a student) and another object (i.e., the reference work from which the student's submission was taken or adapted). In contrast, it is often the case that no such “proof” is available from AI Detection Tools.
Due to the possible fallibility, possible misestimation of fallibility, and possible absence of proof to accompany assertions of AI use by AI Detection Tools, it is recommended that instructors use such tools with great caution and with full recognition of their limitations. In general, the “evidence” provided by such tools should be only part of an instructor’s case when accusing a student of academic misconduct.
The scope of applicability of the Academic Integrity Conduct Process is in no way limited by these guidelines.
ARTIFICIAL INTELLIGENCE (AI). The following definition is from the IEEE-USA Board of Directors: “The theory and development of computer systems able to perform tasks normally requiring human intelligence such as, visual perception, speech recognition, learning, decision-making, and natural language processing.”
ARTIFICIAL INTELLIGENCE TOOL (AI Tool). Any platform (i.e., any computer [hardware] or program [software], or any part of a piece of hardware or software), in which artificial intelligence is leveraged to assist the user of the platform with a user-specified task. It is recognized that this definition is broad in scope; the justification for this breadth is the fact that many platforms already incorporate artificial intelligence, and it is anticipated that this breadth of adoption will only grow in the future. Appendix A “AI Tools: Scope and Use at Drexel University” presents a partial current snapshot of this landscape, with the recognition it will require regular updates to maintain relevance.
AI DETECTION TOOL. Any platform (i.e., any computer [hardware] or program [software], or any part of a piece of hardware or software) intended to assess whether or not AI or an AI Tool has been used to create a digital object (e.g., text, audio, image, video).
CHATBOTS. AI systems designed to automatically interact through the interpretation of natural language.
AUTOMATIC WRITING EVALUATION. AI-driven systems that use natural language processing to automatically provide feedback on written text submitted to the system.
INTELLIGENT TUTORING SYSTEMS (ITS). AI-driven tools that can provide step-by-step tutorials, learning exercises, recommendations, prompts, and assessments, individualized for learners.


EFFECTIVE DATE: November 20, 2023 (Expedited)
 
