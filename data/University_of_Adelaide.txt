University of Adelaide official policy on generative AI Artificial Intelligence
https://libguides.adelaide.edu.au/c.php?g=959585&p=6965069
Generative artificial intelligence (AI) is an emerging and rapidly evolving technology. With increasing student interest and engagement with AI platforms, the University Library is keen to play a role in supporting the appropriate application and use of these resources in work and assignments. AI tools can be useful and beneficial in your studies, provided they are used responsibly and ethically to support your learning and good academic integrity practices are maintained.
This page will be updated to reflect the changing AI landscape. Please continue to check this How Do I Guide to keep up to date on emerging AI trends in the academic space and latest guidelines for using AI tools in your studies.
You can find out more about academic integrity and AI technologies on the Student Academic Skills & Support webpage, including the Academic Integrity unit's initial guidelines for students.
Below are some useful links from higher education institutions across Australia that discuss best practice use of AI tools for students and researchers:
Generative AI tools may be able to:
(Content derived from University of Queensland Library Guide on Artificial Intelligence CC BY-NC 4.0)
There is potential for you to use Generative AI responsibly to assist you in your studies but there are also risks that you must consider when using this type of technology. Information obtained from ChatGPT should not be considered a primary source and should be used in conjunction with other sources. Additionally, since AI models can sometimes produce incorrect or biased information, it's crucial to verify information obtained from ChatGPT with other sources before including it in your work. It is important to be aware that Information provided by generative AI tools may be:
Generative AI, such as ChatGPT, have limitations on what information they can provide. For example, ChatGPT doesn’t have access personal information or private data, events that happen after its knowledge cut off (2021), information that is not available in written or spoken form or information about very specific or niche topics that are not widely available publicly.
As with all sources you use in your assignments, you should critically evaluate them for their quality and biases. Learn now to evaluate key information sources, like generative AI tools, in our Library Essentials courses:
(Content derived from University of Queensland Library Guide on Artificial Intelligence CC BY-NC 4.0)
ChatGPT can provide references if you tell it to, however this can be very risky as ChatGPT can provide false, fake or incorrect references.  References can sound plausible, drawing on real journal titles or authors, which means it can be difficult to tell on first glance whether they are real or made up. Another issue is that references may not also match to the correct source of information. Both are forms of "AI hallucination" where generative AI tools, particularly those that use natural language processing, generate false information, summaries or other assertions, sometimes due to coding or training issues, or lack of knowledge on a particular topic. For example, ChatGPT provided the following summary and citation for a prompt about needing a journal article on overgrown teeth in guinea pigs:
"Title: Dental disease in guinea pigs: A retrospective study of 100 cases (2017). Authors: L. Jekl, E. Knotek, M. Jeklova, V. Hauptman, and V. Jeklova. Journal: Journal of Exotic Pet Medicine. This study aimed to investigate the prevalence and clinical features of dental disease in guinea pigs. The authors conducted a retrospective study of 100 cases of dental disease in guinea pigs, examining medical records and radiographs. They found that dental disease was a common problem in guinea pigs, with overgrown teeth being the most common clinical presentation. Other common clinical features included weight loss, anorexia, and drooling. The study also found that dental disease was often associated with other health problems, such as respiratory disease and gastrointestinal disease" [Source: ChatGPT response to a prompt about locating an academic journal article, 18 April 2023].
This article does not exist. The journal is real, and L. Jekl published an article on dental disease in guinea pigs in this journal, but with different co-authors and in a different year. While the summary and citation sound plausible, this reference is not real, demonstrating the importance of double-checking any references generated by ChatGPT.
See below for some links that discuss AI hallucination in more detail:
