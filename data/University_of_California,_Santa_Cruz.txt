University of California, Santa Cruz official policy on generative AI Artificial Intelligence
https://tlc.ucsc.edu/resources/artificial-intelligence-in-teaching-learning/
The Teaching & Learning Center
The field of Artificial Intelligence (AI) is progressing rapidly and in bewildering ways. Applications of AI have become common in almost every sort of human interaction, including teaching and learning. You’ll find guidance below for thinking about the role of AI in your classes, writing a proprietary AI policy, and responding to unauthorized AI use. 
AI is an umbrella term for any computer program that simulates cognitive processes. Many different AI platforms are now accessible for public use. ChatGPT is perhaps the most widely used among university students and of most concern to faculty. ChatGPT and similar AI technologies use predictive algorithms to generate written text. They work by analyzing a large dataset of text to learn the patterns and relationships among words and phrases. When given a prompt or a starting point, these programs can generate text that is similar to text they have seen before. They can answer one-off prompts or engage in dialogue. It is often hard to distinguish their output from human writing. 
There’s still quite a bit that AI and ChatGPT can’t do. These limitations may help you understand its ability and inspire how you design assignments. For instance (for now), ChatGPT cannot fact-check; engage in self-reflection; write about anything that happened after 2021; create infographics, interactive maps, videos, or memes; make predictions about the future; browse or summarize content from the internet (it was built with a specific data set and does not search the internet); cite specific examples or quotations from another text; or draw connections between course content and visual materials. 
Some students use AI in situations similar to those in which they might formerly have engaged in plagiarism. They may resort to ChatGPT because of a heavy course load or work schedule, overwhelming family obligations, or because they don’t understand the assignment. They may use ChatGPT because they are unaware of what is allowed and what is not. 
Your students may also use ChatGPT in productive ways:
Whether you discourage or encourage the use of AI, you should talk to your students about your expectations early and often—on the first day of the quarter and in preparation for all major assessments. 
Take a proactive approach to AI. Regardless of your own feelings about it, AI is here to stay – eventually, you will need to find ways to either actively work with it or to minimize its downsides. The application and utility of AI will inevitably be different in different disciplines. In those disciplines wherein professional practitioners use AI to save time spent on more tedious tasks, for instance, teaching practical AI use may confer future employment benefit on students. In disciplines such as writing, however, it may detract from students’ opportunities to develop skills. Your approach to AI use should address the specificities of your discipline, your department, and your professional practice as a scholar and teacher. Keep in mind, too, that your students are looking to you as a model for standards of scholarship within and beyond your discipline. If they perceive apathy in your approach to the ethical use of AI, they may follow your lead.
Some instructors have chosen to incorporate AI use into their assignments with the proviso that students clearly cite where they have used it. Here are just a few of the wide-ranging possibilities for this technology: 
Should you include an AI-use policy in your syllabus? Absolutely. Craft an AI policy that aligns with the specific needs and ethics of your discipline, your department, and your course. Rather than providing institutional language, we offer the customizable formula below for constructing your own policy. Sample syllabus language follows this guide to give you some ideas for creating a proprietary version that suits your needs. You can also refer to statements used in courses at UC Santa Cruz or to this crowd-sourced document that contains syllabus language samples from higher-ed institutions all over the U.S. 
Note that unless your AI policy is uniformly prohibitive (including tools such as grammar and spelling checkers), your guidelines will be clearer to students as a standalone statement than as a brief part of your general academic integrity policy. 
The samples provided below are from a CSE course and a Sociology course, respectively. Your message to students about the use of AI (and academic integrity in general) should be specific to your course and discipline and reflect your teaching philosophy, the priorities of your department, and the conventions of your field. 
Sample 1:
Sample 2:
Integrity – other people’s perception of your word as true – is one of the most valuable assets you can cultivate in life. Being attentive to integrity in academic settings allows others to trust that you have completed work for which you are taking credit. This is symbolic of the public trust from which you will benefit in your future occupation and activism after you graduate from UCSC. 
The creativity of your words, expression, understanding, and knowledge matters a great deal in your work as a sociologist, and it matters to me. My AI policy reflects the emphasis our discipline places on original thought and scholarship.
While conventional plagiarism is often easy to identify, text produced by AI may be indistinguishable from other student work. Some AI-generated text contains the telltale signs of a large language model: plausible but illogical arguments, invented “facts,” prose that feels flat. But trying to detect AI-generated text is a losing game, and it will only become more difficult as the technology advances. 
There are programs that detect AI-generated text with varying levels of accuracy, but they may only be used at UC Santa Cruz if the tool is hosted locally and data is protected from external access, the tool is contracted through campus Purchasing, or if you obtain prior approval from students. Without meeting one of these criteria, the use of AI detectors may violate the Family Educational Rights and Privacy Act (FERPA), which prevents the unauthorized sharing of student work. The guidance is explained in detail in this March 20, 2023 communication to faculty. 
A less direct—but still informative—approach is to enter your own assignment prompt into ChatGPT a few times to see what it produces. Platforms like ChatGPT don’t generate the same response twice, but they do generate similar responses across multiple iterations. Certain words and phrases reappear; arguments and analyses are markedly similar. You may compare AI-generated text to student submissions without prior approval. If applicable, share the output with your teaching team and ask them to familiarize themselves with it. 
A note of caution: If you plan to use a detection tool, proceed carefully, as detection tools occasionally produce false positives, which can harm student-instructor relations when false accusations are made. 
If you suspect that a student’s submission was generated by AI, start with a conversation. Students who completed their own work are generally able to explain and defend their process. Assume the best of your students and consider your evidence carefully before coming to conclusions about a student’s behavior. Just as an AI detector can return a false positive, your intuition is fallible. An unfounded accusation against one student can damage your relationship with all of your students.
If you are still convinced that the student did not complete the assignment in accordance with your AI/academic integrity policy, follow up with the action items you previously identified in your policy: such as no credit for the assignment, referral to college provost, etc. Describe this process clearly in your syllabus to ensure that your students perceive it as being fairly applied across the class. 
If you choose to pursue institutional disciplinary action based on suspected academic misconduct, be sure to clearly document the reasoning behind your suspicions.
There is no way to prevent AI use in your classroom, but you have more influence than you might realize on students’ thinking and decision-making. The following is a non-exhaustive list of strategizes you might consider incorporating in concert with one another: 
Faculty presentations from Leilani H. Gilpin, Assistant Professor of Computer Science and Engineering; Amy Vidali, Chair & Associate Teaching Professor, Writing Program; Zac Zimmer, Associate Professor of Literature; and Jennifer Parker, Professor of Art. 
Watch recording of the event
