University of Delaware official policy on generative AI Artificial Intelligence
https://ctal.udel.edu/advanced-automated-tools/
This webpage focuses primarily on course policies, how to discuss those policies, and some examples of assignments that address or make use of advanced technologies such as generative AI. Additional resources about the use of artificial intelligence tools in teaching and learning, including important considerations for faculty considering the use of these tools in their courses, can be found on the webpage for the university’s Artificial Intelligence for Teaching and Learning Working Group.
 Advanced automated tools – artificial intelligence or machine learning tools such as ChatGPT or Dall-E 2 that are sometimes described as “generative” or “autogenerative” tools – use sophisticated technology and very large data sets to create realistic writing, images, or other artifacts in response to natural language queries and prompts. They are very easy to use and some of their output is very difficult to distinguish from human-generated material.
This website provides context and practical suggestions for faculty who are addressing the use of advanced automated tools in their course(s). Should students be allowed to use these tools? What are the most pressing issues – practical, pedagogical, and ethical – related to the use of these tools? How can we support their learning about these tools and the many complex, interesting, and rapidly-developing issues that surround them?
These tools are readily accessible to students and have the potential to significantly change some aspects of traditional Western higher education, especially assignments that require students to write or create other artifacts that can easily be created or changed using one of these tools. Although there is research that supports the notion that some automated tools can help students learn and improve skills such as writing (e.g., Wilson, Olinghouse, & Andrada (2014)), the extent of the impact of these newer tools is unknown and subject to debate. However, their accessibility and ease-of-use makes it likely that some students will at least experiment with these tools and be expected to use similar tools after graduation.
Just as faculty have previously adapted their teaching to accommodate the use of other tools and advancements in technology, faculty are encouraged to develop and share with students a coherent approach to the use or non-use of these tools in their courses.
In each course, at least four possible approaches seem plausible in terms of student use of these tools:
Each approach is discussed below with some thoughts and considerations; possible syllabus language for each approach is included in a separate section below. Regardless of the approach selected, faculty should explicitly discuss with students the approach and its underlying rationale.
If use of these tools is prohibited, limited, or must be documented, faculty should also consider if they should include an explicit reminder about plagiarism and whether use or misuse of these tools would be considered plagiarism.
In courses where students are expected to independently produce work without any collaboration or the use of external tools, it may be appropriate to not allow any use of these tools. In these situations, it would be most helpful to not only explicitly tell students this but also explain to them why they are not allowed to collaborate or use tools. An honest, respectful discussion about why it’s important for students to work independently in this particular class can help students understand that critical context and broader (academic, professional, or disciplinary) norms and expectations.
In some courses, it may be appropriate to use these tools in some scenarios or on some assignments but not in others. In those situations, faculty should clearly communicate with students when and how they can and cannot use these tools. It would be helpful to also make clear the rationale for allowing these tools in some situations but not allowing them in others; this could be an open discussion and exploration of (academic, professional, or disciplinary) norms and expectations or it could be a brief explanation of your thinking and expectations. Remember that it would also be helpful to explicitly (a) note how students should cite or otherwise acknowledge these tools, with one or more examples, and (b) help students understand the limits and appropriate uses of these tools.
In courses where students are allowed or expected to collaborate or use advanced tools, it may be appropriate to allow students to use these tools throughout the class as long as they explicitly cite or otherwise acknowledge the use of these tools. Remember that it would also be helpful to explicitly (a) note how students should cite or otherwise acknowledge these tools, with one or more examples, and (b) help students understand the limits and appropriate uses of these tools.
In courses where students are allowed or expected to frequently collaborate or use advanced tools, it may be appropriate to allow students to use these tools throughout the class without requiring that they explicitly cite or otherwise acknowledge the use of these tools. In these classes, it is critical that students understand the limits and appropriate uses of these tools.
If students are allowed to use these tools, faculty should be able to help students understand:
“Computational thinking” is one of UD’s General Education objectives, the set of skills and knowledge that we expect all UD undergraduate students to attain through their educational experience. Meaningfully addressing the use of these tools – probing their limits, exploring their ethical uses, and meaningfully integrating them into practices – in the context of a specific course or discipline can be a very effective way of helping students build computational thinking skills and knowledge (Martín-Núñez, et al. (2023) explicitly supports this hypothesis).
Four examples of policy statements suitable for inclusion on a course syllabus are listed below. These statements should be modified to fit the specific context of each course and syllabus e.g., change from the impersonal “students” to the personal “you” if that language is consistently used throughout the syllabus.
Students are not allowed to use advanced automated tools (artificial intelligence or machine learning tools such as ChatGPT or Dall-E 2) on assignments in this course. Each student is expected to complete each assignment without substantive assistance from others, including automated tools.
Students are allowed to use advanced automated tools (artificial intelligence or machine learning tools such as ChatGPT or Dall-E 2) on assignments in this course if instructor permission is obtained in advance. Unless given permission to use those tools, each student is expected to complete each assignment without substantive assistance from others, including automated tools.
You may also want to require students to explicitly document or acknowledge their use of this tool. Potential language for that:
If permission is granted to use advanced automated tools (artificial intelligence or machine learning tools such as ChatGPT or Dall-E 2), they must be properly documented and credited. Text generated using ChatGPT-3 should include a citation such as: “Chat-GPT-3. (YYYY, Month DD of query). “Text of your query.” Generated using OpenAI. https://chat.openai.com/” Material generated using other tools should follow a similar citation convention.
You may also want to require students to provide a brief explanation of how they used a particular tool. For example:
If a tool is used in an assignment, students must also include a brief (2-3 sentences) description of how they used the tool.
Students are allowed to use advanced automated tools (artificial intelligence or machine learning tools such as ChatGPT or Dall-E 2) on assignments in this course if that use is properly documented and credited. For example, text generated using ChatGPT-3 should include a citation such as: “Chat-GPT-3. (YYYY, Month DD of query). “Text of your query.” Generated using OpenAI. https://chat.openai.com/” Material generated using other tools should follow a similar citation convention.
You may also want to require students to provide a brief explanation of how they used a particular tool. For example:
If a tool is used in an assignment, students must also include a brief (2-3 sentences) description of how they used the tool.
Students are allowed to use advanced automated tools (artificial intelligence or machine learning tools such as ChatGPT or Dall-E 2) on assignments in this course; no special documentation or citation is required.
Even if students are not required to cite the tool(s), you may want to require them to provide a brief explanation of how they used a particular tool. For example:
If a tool is used in an assignment, students must also include a brief (2-3 sentences) description of how they used the tool.
The widespread accessibility of these tools – they are mostly free, easy to access, and easy to use – may motivate many faculty to reexamine assignments and activities to ensure they take into account students’ potential use of these tools. That can include an explicit incorporation of these tools or a design that implicitly dissuades students from using these tools. Further examples, including some that are very detailed, are included below in the “Resources” section.
Courses that allow the use of advanced automated tools may want to focus on improving students’ use and understanding of these tools or at least helping them have a clear understanding of the ethical and effective uses of these tools. Below are some examples of assignments that might help students develop a deeper understanding of these kinds of tools. Before incorporating these tools into assignments, however, you should consider whether all students can access these tools and how they access them e.g., is it ethical to require students to give a company their phone number and e-mail address when the university has no relationship with that company or assurances that information will be protected or ethically used?
Courses that do not allow the use of these tools may want to modify assignments to ensure that students cannot easily use these tools. This may most easily be done by understanding and addressing the weaknesses of these tools – no ability to synthesize, lack of the specific context of a particular class and discipline, refusal to provide sources, etc. Modifications to assignments that may dissuade the use of these tools:
There have been and continue to be efforts to develop tools that can detect materials generated by these advanced automated tools. The level of accuracy of these detection tools varies and will continue to change as both the generators and the detectors continue to change and are updated. Many experts are skeptical of the quality of these tools with significant concerns about “false positives” that can potentially be used to accuse students of using these tools when they have not used these tools; our colleagues at Temple University have written about this, including their own evaluation of TurnItIn’s tool. The difficulty of creating an accurate detection tool led the creators of ChatGPT to remove their own tool, AI Text Classifier, and note in their Educator FAQs that “none of [the detection tools] have proven to reliably distinguish between AI-generated and human-generated content.”
Examples of detection tools focused on text that may have been developed by ChatGPT or similar tools include:
Instead of (solely) focusing on detecting the use of the tools or attempting to design assignments that the current tools cannot complete, The MLA-CCCC (Modern Language Association and Conference on College Composition and Communication) Joint Task Force on Writing and AI has several recommendations for faculty. This group focuses on writing and writing assignments but these recommendations can easily be extended to other domains.
Thank you to:
Revised by Kevin R. Guidry on March 22, 2024
Designed by Elegant Themes | Powered by WordPress
