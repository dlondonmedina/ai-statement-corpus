University of Wisconsin - Oshkosh official policy on generative AI Artificial Intelligence
https://uwosh.edu/cetl/generative-ai-recommendations-and-best-practices/
Amidst the ever-evolving landscape of generative AI, we recognize the profound uncertainty that instructors have been navigating. The rapid advancements in this field have led to questions and considerations that can be both intriguing and overwhelming.
As we explore the potential of AI in education, remember that you are not alone. The CETL team is working hard to provide comprehensive materials to assist you as we move forward with this emerging technology. Watch for additional resources to be released soon.  In the meantime here’s what most experts have agreed on in terms of positive responses to this issue in the classroom:  
Click the “+” next to each tip below to read more.
Let’s start with some good news. University instructors have been aware of and responding to issues of plagiarism for many years. One of the first steps toward addressing plagiarism and cheating through the use AI is to have authentic conversations with students early in the semester about the positive promise of ChatGPT and other AI tools as well as the challenges posed by them in relation to academic integrity and other ethical issues.  
 
In this conversation, you can set up your expectations for students in relation to AI. If you are allowing AI tools in some instances but not others, explain how your choices fit into your larger vision of teaching and learning and, more specifically, your learning outcomes. How does the use of AI tools allow students to achieve some learning outcomes but not others? Sharing your vision with students in this way will position them to see the macro goals of your course and how your allowance or restriction of AI fits into them.
As we grapple with what our approach to AI will be, it’s important to remember that, even before AI, students often struggled to understand what academic integrity is and what is expected of them in relation to it. They often come into a course with misconceptions of what cheating or plagiarism looks like. Therefore, the more we can address these misconceptions, the better students will understand what is expected of them. Through this greater understanding, they will be positioned to meet your requirements in relation to academic integrity and the use of AI. Explaining how AI might lead students into plagiarism or cheating and providing students’ guidance about what you consider acceptable and unacceptable in approaching assignments and coursework generally will set them up for greater success.
As with all aspects of your syllabus, the guidance on AI use should not simply lay out  punishments or threats about what will happen when students misuse AI. In fact, this  kind of language can be off-putting to students and may raise their anxiety along with  their resistance to the instructions. Instead, consider teaching about AI and using an  even-handed tone about the consequences that come with plagiarizing and  cheating even in the section on restrictions and consequences. The first link below  provides a great example of engaging students on ChatGPT and setting up boundaries  for its use while teaching students about AI as well. For a syllabus that explains what  “responsible use of AI” looks like while laying out the consequences for misuse in a  respectful way, which the first does not, look at the second syllabus statement below.
Examples
The last two examples above came from Lance Eaton’s compilation of  instructors’ syllabi statements on course polices for the use of AI. This google doc is full of example policies and is continuing to grow.
The role generative AI will play in the way we work and write will continue to change and evolve; organizations that set the standards for professional writing have offered additional insights on ways we may be able to use AI responsibly by citing its use in professional and academic settings.
At colleges and universities across the nation, there is concern about the risks to personal and institutional security with the growth of generative AI’s abilities. So, you should be aware that, if you enter data into generative AI tools, it is not private. The information is collected and stored and could be shared with and used by unknown users. A number of universities warn that sharing information with AI tools is similar to posting it on a public website.
Data that is classified as High or Moderate Risk cannot be shared with AI tools. Only Low Risk data and information that is considered already available as part of the public domain can be shared.
UW Oshkosh has two documents that help determine how to handle data on our campus.  We recommend reviewing both so you are familiar with the types of data you may have access to and are familiar with the level of security they require.
At some point, you may be interested in using AI as a teaching assistant or using it in some other way to get feedback about students’ work. If you use it to evaluate student work, you should not share students’ names, grades, and/or student IDs because inputting this information can expose students to the potential risk of having that information used inappropriately. In turn, sharing a student assignment to be graded, even with personal information removed, is a violation of privacy. If you want to use AI as a collaborator in grading student assignments, you will need to ask for students’ permission to do so and be certain they understand that, if they refuse to take part, there will be no repercussions. 
Many experts have concerns about the sharing of private data with AI models and the use to which that data might be put. Let your students know the concerns experts have about sharing personal info with AI.
This website provides a sample syllabus statement about the tool’s collection of data and suggestions on how to talk to students about this topic:
Privacy and Other Ethical Considerations
 
We recommend exploring the use of ChatGPT, Bing Chat, and Google Bard or other AI models in order to understand their capabilities and shortcomings. One way to approach this exploration is to evaluate the AI tool in relation to your own discipline. You could engage AI on concepts central to your field and ask about its understanding of them. Other ideas include inputting problems or prompts used in your course to evaluate the generative AI’s ability to solve the problem or respond to the prompt or providing your own version of a completed assignment and asking AI to evaluate it. You might also ask for input on improving your prompt for an assignment and evaluate the response.
If you’re new to working with generative AI, here’s a useful overview of how to write prompts for ChatGPT which also offers some caveats on the current limits of its usefulness.
Consider experimenting with using AI to complete tasks required in your daily life.  Using the technology regularly will help you gain a better understanding of its strengths and flaws.
 
Many leaders in education are hailing the positive contributions that AI can make to higher education. The following resources provide ways that generative AI can be leveraged to assist students in achieving higher-level learning outcomes and strategies for incorporating engagement with generative AI within your assignments.
Another major concern in education with the growth of generative AI is the issue of equity for students. As generative AI moves from being freely available to having a cost, low SES students, who are often also first-generation college students, will experience unequal access to generative AI. Many scholars also point out that generative AI is often “culturally insensitive” and, thus, could harm minoritized students. The articles below lay out some of the dangers of generative AI in relation to equity and also provide ways that it can be useful to minoritized students such as through increasing student accessibility and providing all students with a chance to improve their communication skills. 
If you teach students how to use AI to benefit their learning, they will see its possibilities. At the same time, they will also learn about its limitations. For example, many AI experts discuss the “hallucinatory” aspect of AI, its making up of answers that sound authentic but aren’t. Through your engaging of students in this kind of learning, they will better grasp how they can use AI to enhance their understanding and how it might expose them if they use it as a substitute for learning.
The following resources will provide ideas and guidance when incorporating AI into your class activities.
In order to position students for success, you will want to give them detailed instructions on how to interact with the AI tool in ways that will benefit their learning. Since the usefulness of AI responses often depends on the quality of the input, your sharing with students how to best form a prompt for the AI tool will assist them in better understanding how the exchange works.
Most experts caution that using AI tools often involves sharing personal information which raises privacy concerns. So, to protect those students who don’t feel comfortable with sharing their information, we recommend offering an alternative assignment as well.
AI is on the rise, remember there are many teaching strategies that have already been developed that encourage greater students’ involvement in learning and, thus, reveal their thinking. These strategies have also been linked to greater student success and promote equity and inclusion in the classroom. They can assist you in confirming that the knowledge being shared by the students is their own. It is one way to counter the intrusion of AI into students’ work. Some examples of teaching and learning approaches that are being hailed once again in this new environment are the following:
Remember you know your content best and your deep knowledge of your discipline can serve to engage your students’ imagination and position them to create unique arguments that AI could not form itself. You might think about particular components of your discipline and your own research in working to create assignments which will be more impermeable to useful AI input: what are the latest developments in your field—in the last year or two; what debates are critical to producing knowledge and new ways of seeing; what has not yet been addressed in your field or not been considered enough; and what recent events might students engage to explore critical topics in your field?
It has been shown that AI has difficulty reproducing debates within a discipline or comparing and contrasting ideas between texts. It struggles with complexity and specificity. Therefore, if you ask students to explore a debate between two experts in your discipline and take a side in relation to the debate, AI would most likely have difficulty providing an accurate answer. Similarly, moving away from the general to the specific can make it less likely AI will be able to provide useful feedback to students. For example, asking students to provide an analysis of a specific part of a text rather than an overview of it can help thwart ChatGPT’s use for cheating and plagiarism. 
 Of course, AI doesn’t know what you taught your students in class. So, you can also ask them to take a side on a debate held in class; sum up the solution, or a range of them, to a problem discussed in class; and expand on a discussion in class, to name a few suggestions.
 
When chat-like generative AI tools became widely available in 2022, many technology companies released applications that promised to identify text written by AI. Although they were initially welcomed, it is becoming increasingly clear that they are not as effective as hoped.
While Turnitin maintains that their detector is effective, they admit that it is most effective when analyzing large pieces of text. It is far less accurate at identifying the usage of AI in smaller paragraphs or sentences and is prone to false positives, identifying text as AI-written when it was actually composed by a human. This theme of unreliablity seems to hold true with other tools too. Open AI, the company that created Chat GPT, shut down their detector at the beginning of August because it was not capable of correctly determining which pieces of text were AI-generated and which were not.
If you choose to use a detector, use with caution and as a way to begin a conversation with students about their writing. They should NOT be used as evidence of academic dishonesty.
We use cookies on this site. By continuing to visit without changing your browser settings to block cookies, you agree to the UW Oshkosh Privacy Notice.
Location
Quick Links
Resources
